{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import src.translation_agent as ta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| num_tokens_in_text: 4\n",
      "ic| 'Translating text as single chunk'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嗨，世界！\n"
     ]
    }
   ],
   "source": [
    "# quick test\n",
    "source_text=\"Hello, world!\"\n",
    "source_lang, target_lang, country = \"English\", \"Chinese\", \"China\"\n",
    "translation = ta.translate(source_lang, target_lang, source_text, country)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| num_tokens_in_text: 672\n",
      "ic| 'Translating text as single chunk'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source text:\n",
      "\n",
      "Last week, I spoke about AI and regulation at the U.S. Capitol at an event that was attended by legislative and business leaders. I’m encouraged by the progress the open source community has made fending off regulations that would have stifled innovation. But opponents of open source are continuing to shift their arguments, with the latest worries centering on open source's impact on national security. I hope we’ll all keep protecting open source!\n",
      "\n",
      "Based on my conversations with legislators, I’m encouraged by the progress the U.S. federal government has made getting a realistic grasp of AI’s risks. To be clear, guardrails are needed. But they should be applied to AI applications, not to general-purpose AI technology.\n",
      "\n",
      "Nonetheless, as I wrote previously, some companies are eager to limit open source, possibly to protect the value of massive investments they’ve made in proprietary models and to deter competitors. It has been fascinating to watch their arguments change over time.\n",
      "\n",
      "For instance, about 12 months ago, the Center For AI Safety’s “Statement on AI Risk” warned that AI could cause human extinction and stoked fears of AI taking over. This alarmed leaders in Washington. But many people in AI pointed out that this dystopian science-fiction scenario has little basis in reality. About six months later, when I testified at the U.S. Senate’s AI Insight forum, legislators no longer worried much about an AI takeover.\n",
      "\n",
      "Then the opponents of open source shifted gears. Their leading argument shifted to the risk of AI helping to create bioweapons. Soon afterward, OpenAI and RAND showed that current AI does not significantly increase the ability of malefactors to build bioweapons. This fear of AI-enabled bioweapons has diminished. To be sure, the possibility that bad actors could use bioweapons — with or without AI — remains a topic of great international concern.\n",
      "\n",
      "\n",
      "The latest argument for blocking open source AI has shifted to national security. AI is useful for both economic competition and warfare, and open source opponents say the U.S. should make sure its adversaries don’t have access to the latest foundation models. While I don’t want authoritarian governments to use AI, particularly to wage unjust wars, the LLM cat is out of the bag, and authoritarian countries will fill the vacuum if democratic nations limit access. When, some day, a child somewhere asks an AI system questions about democracy, the role of a free press, or the function of an independent judiciary in preserving the rule of law, I would like the AI to reflect democratic values rather than favor authoritarian leaders’ goals over, say, human rights.\n",
      "\n",
      "I came away from Washington optimistic about the progress we’ve made. A  year ago, legislators seemed to me to spend 80% of their time talking about guardrails for AI and 20% about investing in innovation. I was delighted that the ratio has flipped, and there was far more talk of investing in innovation.\n",
      "\n",
      "Looking beyond the U.S. federal government, there are many jurisdictions globally. Unfortunately, arguments in favor of  regulations that would stifle AI development continue to proliferate. But I’ve learned from my trips to Washington and other nations’ capitals that talking to regulators does have an impact. If you get a chance to talk to a regulator at any level, I hope you’ll do what you can to help governments better understand AI.\n",
      "\n",
      "------------\n",
      "\n",
      "Translation:\n",
      "\n",
      "上周，我在美国国会大厦参加了一个活动，讨论了人工智能与监管的问题，立法和商业领域的领导者们均有出席。我对开源社区在抵制可能抑制创新的规定方面所取得的进展感到欣慰。然而，反对开源者持续调整他们的论点，目前关注的焦点是开源对国家安全的潜在影响。我希望我们都能继续捍卫开源！\n",
      "\n",
      "在与立法者的交流中，我对美国联邦政府在理解AI风险方面的实际进展感到鼓舞。明确地说，我们需要设立一些边界。但这些限制应当针对AI应用，而非通用型AI技术。\n",
      "\n",
      "尽管如此，正如我之前所撰写的，一些公司急切地想要限制开源，这可能是为了保护他们在专有模型上的巨额投资，以及阻止竞争对手。观察他们论点的演变一直引人入胜。\n",
      "\n",
      "例如，大约一年前，人工智能安全中心的“关于AI风险的声明”警示，AI可能导致人类灭绝，激起了对AI控制的恐慌。这让华盛顿的领导人感到震惊。但AI领域的许多人指出，这种反乌托邦科幻场景在现实中缺乏根据。六个月后，我在美国参议院的AI洞察论坛作证时，立法者们对AI控制的问题已不再那么担忧。\n",
      "\n",
      "之后，反对开源者改变了策略，将主要论点转向了AI协助制造生物武器的风险。不久后，OpenAI和RAND的研究表明，当前的AI并未显著提升恶意行为人士制造生物武器的能力。对于AI助力生物武器的担忧已经减弱。当然，不良行为人士使用生物武器——无论是否借助AI——依然是一个全球关注的重大议题。\n",
      "\n",
      "最新的反对开源AI的论点涉及国家安全。AI对经济竞争和战争均有帮助，反对开源者认为美国应确保对手无法接触到最新的基础模型。尽管我不希望威权政府使用AI，特别是发动不义之战，但大型语言模型（LLM）已无法收回。如果民主国家限制访问，威权国家便会乘虚而入。有朝一日，当某个角落的孩子向AI系统询问关于民主、自由新闻的角色或独立司法在维护法治中的作用时，我更希望AI能体现民主价值观，而非偏向威权领导者的目标，比如忽视人权。\n",
      "\n",
      "我从华盛顿归来，对我们所取得的进展持乐观态度。一年前，立法者们似乎将80%的时间用于讨论AI的限制措施，而只有20%的时间关注创新投资。我欣喜地看到这一比例已彻底反转，如今更多的是关于创新投资的讨论。\n",
      "\n",
      "除了美国联邦政府之外，全球还有众多司法管辖区。不幸的是，支持可能抑制AI发展的监管论点仍在扩散。但我在访问华盛顿和其他国家首都时学到，与监管者的交流确实能够产生影响。如果你有机会与各级监管者交谈，我希望你能尽己所能帮助政府更深入地理解AI。\n"
     ]
    }
   ],
   "source": [
    "source_lang, target_lang, country = \"English\", \"Chinese\", \"China\"\n",
    "\n",
    "relative_path = \"examples/sample-texts/sample-short1.txt\"\n",
    "relative_path = \"examples/sample-texts/sample-long1.txt\"\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "full_path = os.path.join(script_dir, relative_path)\n",
    "\n",
    "with open(full_path, encoding=\"utf-8\") as file:\n",
    "    source_text = file.read()\n",
    "\n",
    "print(f\"Source text:\\n\\n{source_text}\\n------------\\n\")\n",
    "\n",
    "translation = ta.translate(\n",
    "    source_lang=source_lang,\n",
    "    target_lang=target_lang,\n",
    "    source_text=source_text,\n",
    "    country=country,\n",
    ")\n",
    "\n",
    "print(f\"Translation:\\n\\n{translation}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
